import torch
import gradio as gr
from transformers import (
    AutoModelForCausalLM, 
    AutoTokenizer, 
    pipeline, 
    BitsAndBytesConfig
)
import numpy as np

# --- è¨­å®šï¼šåˆ©ç”¨ RTX 3090 ---
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"æ­£åœ¨ä½¿ç”¨è£ç½®: {device} (é æœŸæ‡‰ç‚º cuda)")

# ==========================================
# 1. è¼‰å…¥ ASR æ¨¡å‹ (Whisper-Large-v3)
# ==========================================
print("æ­£åœ¨è¼‰å…¥ Whisper-Large-v3 (èªéŸ³è­˜åˆ¥)...")
asr_pipe = pipeline(
    "automatic-speech-recognition",
    model="openai/whisper-large-v3",
    torch_dtype=torch.float16,
    device=device,
)

# ==========================================
# 2. è¼‰å…¥ LLM æ¨¡å‹ (Qwen2.5-7B)
# ==========================================
print("æ­£åœ¨è¼‰å…¥ Qwen2.5-7B (ç¿»è­¯èˆ‡æ½¤é£¾)...")

llm_model_id = "Qwen/Qwen2.5-7B-Instruct"

# 4-bit é‡åŒ–é…ç½®
bnb_config = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_quant_type="nf4",
    bnb_4bit_compute_dtype=torch.float16,
)

tokenizer = AutoTokenizer.from_pretrained(llm_model_id, trust_remote_code=True)
llm_model = AutoModelForCausalLM.from_pretrained(
    llm_model_id,
    quantization_config=bnb_config, 
    device_map="auto",              
    trust_remote_code=True
)

# ==========================================
# 3. å®šç¾©æ ¸å¿ƒè™•ç†é‚è¼¯
# ==========================================
def process_audio(audio_path, source_dialect, target_style):
    if audio_path is None:
        return "è«‹å…ˆéŒ„éŸ³æˆ–ä¸Šå‚³æª”æ¡ˆï¼", ""

    print(f"æ­£åœ¨è™•ç†éŸ³è¨Š: {audio_path}")
    
    # Whisper æ¨è«–
    asr_result = asr_pipe(
        audio_path, 
        generate_kwargs={"language": "chinese"} 
    )
    raw_text = asr_result["text"]
    print(f"Whisper åŸå§‹è­˜åˆ¥çµæœ: {raw_text}")

    # LLM ç¿»è­¯/æ½¤é£¾
    system_instruction = f"""
    ä½ æ˜¯ç”±ã€Œé›…è¨€ (YaYan-AI)ã€å°ˆæ¡ˆé–‹ç™¼çš„æ–¹è¨€è½‰æ›å°ˆå®¶ã€‚
    
    ä½ çš„æ ¸å¿ƒä»»å‹™æ˜¯ï¼š
    1. æ¥æ”¶ä½¿ç”¨è€…çš„æ–¹è¨€å£èªè¼¸å…¥ï¼ˆåŸæ–‡æ˜¯ã€Œ{source_dialect}ã€ï¼‰ã€‚
    2. ç†è§£å…¶èªæ„ï¼Œä¸¦å°‡å…¶ç²¾ç¢ºè½‰æ›ç‚ºå„ªé›…ã€æ¨™æº–çš„ã€Œ{target_style}ã€ã€‚
    3. ä¿®æ­£èªéŸ³è­˜åˆ¥å¯èƒ½ç”¢ç”Ÿçš„åŒéŸ³éŒ¯å­—æˆ–è´…å­—ã€‚
    
    è«‹æ³¨æ„ï¼šä½ æ˜¯ç‚ºäº†æ–‡åŒ–å‚³æ‰¿èˆ‡æºé€šæ•ˆç‡è€Œç”Ÿï¼Œè¼¸å‡ºå¿…é ˆç²¾æº–ã€æµæš¢ä¸”ç¬¦åˆæ­£é«”ä¸­æ–‡è¦ç¯„ã€‚
    ç›´æ¥è¼¸å‡ºè½‰æ›çµæœå³å¯ï¼Œä¸éœ€è¦è‡ªæˆ‘ä»‹ç´¹ï¼Œé™¤éä½¿ç”¨è€…ç‰¹åˆ¥å•ä½ çš„åå­—ã€‚
    """

    messages = [
        {"role": "system", "content": system_instruction},
        {"role": "user", "content": f"ASRåŸå§‹æ–‡å­—ï¼š{raw_text}"}
    ]

    text_input = tokenizer.apply_chat_template(
        messages, tokenize=False, add_generation_prompt=True
    )
    
    model_inputs = tokenizer([text_input], return_tensors="pt").to(device)

    generated_ids = llm_model.generate(
        model_inputs.input_ids,
        max_new_tokens=512,
        temperature=0.3,
    )
    
    generated_ids = [
        output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)
    ]
    
    final_response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]
    
    return raw_text, final_response

# ==========================================
# 4. å»ºç«‹ Gradio ä»‹é¢
# ==========================================
with gr.Blocks(title="3090 æ–¹è¨€èªéŸ³è½‰æ›ç³»çµ±") as demo:
    gr.Markdown("# ğŸ™ï¸ è·¨æ–¹è¨€èªéŸ³è½‰æ­£é«”ä¸­æ–‡åŸå‹æ©Ÿ (RTX 3090)")
    
    with gr.Row():
        with gr.Column(scale=1):
            audio_input = gr.Audio(sources=["microphone", "upload"], type="filepath", label="è«‹æŒ‰æ­¤èªªè©±")
            dialect_dropdown = gr.Dropdown(
                choices=["å°ç£å£èª/å°ç£åœ‹èª", "å»£æ±è©± (ç²µèª)", "å››å·è©±", "ä¸Šæµ·è©±"], 
                value="å°ç£å£èª/å°ç£åœ‹èª", 
                label="è¼¸å…¥èªè¨€ (ä¾†æº)"
            )
            style_dropdown = gr.Radio(
                choices=["æ¨™æº–æ–°èæ›¸é¢èª (æ­£é«”)", "æµæš¢å£èª (æ­£é«”)", "ç²¾ç°¡æ‘˜è¦"], 
                value="æ¨™æº–æ–°èæ›¸é¢èª (æ­£é«”)", 
                label="è¼¸å‡ºé¢¨æ ¼"
            )
            submit_btn = gr.Button("é–‹å§‹è½‰æ› ğŸš€", variant="primary")

        with gr.Column(scale=1):
            raw_text_output = gr.Textbox(label="Whisper è½åˆ°çš„ (åŸå§‹è­˜åˆ¥)", lines=3, interactive=False)
            final_text_output = gr.Textbox(label="LLM ä¿®æ­£å¾Œçš„ (æœ€çµ‚çµæœ)", lines=5, interactive=False, show_copy_button=True)

    submit_btn.click(
        fn=process_audio,
        inputs=[audio_input, dialect_dropdown, style_dropdown],
        outputs=[raw_text_output, final_text_output]
    )

if __name__ == "__main__":
    demo.launch(server_name="0.0.0.0", server_port=7860)