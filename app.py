import torch
import gradio as gr
from transformers import (
    AutoModelForCausalLM, 
    AutoTokenizer, 
    pipeline, 
    BitsAndBytesConfig
)
import numpy as np

# --- è¨­å®šï¼šåˆ©ç”¨ RTX 3090 ---
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"æ­£åœ¨ä½¿ç”¨è£ç½®: {device} (é æœŸæ‡‰ç‚º cuda)")

# ==========================================
# 1. è¼‰å…¥ ASR æ¨¡å‹ (Whisper-Large-v3)
# ==========================================
print("æ­£åœ¨è¼‰å…¥ Whisper-Large-v3 (èªéŸ³è­˜åˆ¥)...")
asr_pipe = pipeline(
    "automatic-speech-recognition",
    model="openai/whisper-large-v3",
    torch_dtype=torch.float16,
    device=device,
)

# ==========================================
# 2. è¼‰å…¥ LLM æ¨¡å‹ (Qwen2.5-7B)
# ==========================================
print("æ­£åœ¨è¼‰å…¥ Qwen2.5-7B (ç¿»è­¯èˆ‡æ½¤é£¾)...")

llm_model_id = "Qwen/Qwen2.5-7B-Instruct"

# 4-bit é‡åŒ–é…ç½®
bnb_config = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_quant_type="nf4",
    bnb_4bit_compute_dtype=torch.float16,
)

tokenizer = AutoTokenizer.from_pretrained(llm_model_id, trust_remote_code=True)
llm_model = AutoModelForCausalLM.from_pretrained(
    llm_model_id,
    quantization_config=bnb_config, 
    device_map="auto",              
    trust_remote_code=True
)

# ==========================================
# 3. å®šç¾©æ ¸å¿ƒè™•ç†é‚è¼¯
# ==========================================
def process_audio(audio_path, source_dialect, target_style):
    if audio_path is None:
        return "è«‹å…ˆéŒ„éŸ³æˆ–ä¸Šå‚³æª”æ¡ˆï¼", ""

    print(f"æ­£åœ¨è™•ç†éŸ³è¨Š: {audio_path}")
    
    # Whisper æ¨è«–
    asr_result = asr_pipe(
        audio_path, 
        generate_kwargs={"language": "chinese"} 
    )
    raw_text = asr_result["text"]
    print(f"Whisper åŸå§‹è­˜åˆ¥çµæœ: {raw_text}")

    # LLM ç¿»è­¯/æ½¤é£¾
    system_instruction = f"""
    ä½ æ˜¯ä¸€ä½ç²¾é€šæ¼¢èªæ–¹è¨€èˆ‡æ¨™æº–æ­£é«”ä¸­æ–‡çš„èªè¨€å°ˆå®¶ã€‚
    ä½¿ç”¨è€…çš„è¼¸å…¥æ˜¯ä¸€æ®µç”±èªéŸ³è­˜åˆ¥ï¼ˆASRï¼‰ç”¢ç”Ÿçš„æ–‡å­—ï¼ŒåŸæ–‡æ˜¯ã€Œ{source_dialect}ã€ã€‚
    ç”±æ–¼æ˜¯å£èªéŒ„éŸ³ï¼Œå¯èƒ½åŒ…å«è´…å­—ã€èªæ°£è©ã€å€’è£å¥æˆ–è­˜åˆ¥éŒ¯èª¤ã€‚
    
    ä½ çš„ä»»å‹™æ˜¯ï¼š
    1. ç†è§£åŸæ–‡çš„èªæ„ã€‚
    2. å°‡å…¶è½‰æ›ç‚ºã€Œ{target_style}ã€ã€‚
    3. ç›´æ¥è¼¸å‡ºè½‰æ›å¾Œçš„çµæœï¼Œä¸è¦è§£é‡‹ï¼Œä¸è¦å›‰å—¦ã€‚
    """

    messages = [
        {"role": "system", "content": system_instruction},
        {"role": "user", "content": f"ASRåŸå§‹æ–‡å­—ï¼š{raw_text}"}
    ]

    text_input = tokenizer.apply_chat_template(
        messages, tokenize=False, add_generation_prompt=True
    )
    
    model_inputs = tokenizer([text_input], return_tensors="pt").to(device)

    generated_ids = llm_model.generate(
        model_inputs.input_ids,
        max_new_tokens=512,
        temperature=0.3,
    )
    
    generated_ids = [
        output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)
    ]
    
    final_response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]
    
    return raw_text, final_response

# ==========================================
# 4. å»ºç«‹ Gradio ä»‹é¢
# ==========================================
with gr.Blocks(title="3090 æ–¹è¨€èªéŸ³è½‰æ›ç³»çµ±") as demo:
    gr.Markdown("# ğŸ™ï¸ è·¨æ–¹è¨€èªéŸ³è½‰æ­£é«”ä¸­æ–‡åŸå‹æ©Ÿ (RTX 3090)")
    
    with gr.Row():
        with gr.Column(scale=1):
            audio_input = gr.Audio(sources=["microphone", "upload"], type="filepath", label="è«‹æŒ‰æ­¤èªªè©±")
            dialect_dropdown = gr.Dropdown(
                choices=["å°ç£å£èª/å°ç£åœ‹èª", "å»£æ±è©± (ç²µèª)", "å››å·è©±", "ä¸Šæµ·è©±"], 
                value="å°ç£å£èª/å°ç£åœ‹èª", 
                label="è¼¸å…¥èªè¨€ (ä¾†æº)"
            )
            style_dropdown = gr.Radio(
                choices=["æ¨™æº–æ–°èæ›¸é¢èª (æ­£é«”)", "æµæš¢å£èª (æ­£é«”)", "ç²¾ç°¡æ‘˜è¦"], 
                value="æ¨™æº–æ–°èæ›¸é¢èª (æ­£é«”)", 
                label="è¼¸å‡ºé¢¨æ ¼"
            )
            submit_btn = gr.Button("é–‹å§‹è½‰æ› ğŸš€", variant="primary")

        with gr.Column(scale=1):
            raw_text_output = gr.Textbox(label="Whisper è½åˆ°çš„ (åŸå§‹è­˜åˆ¥)", lines=3, interactive=False)
            final_text_output = gr.Textbox(label="LLM ä¿®æ­£å¾Œçš„ (æœ€çµ‚çµæœ)", lines=5, interactive=False, show_copy_button=True)

    submit_btn.click(
        fn=process_audio,
        inputs=[audio_input, dialect_dropdown, style_dropdown],
        outputs=[raw_text_output, final_text_output]
    )

if __name__ == "__main__":
    demo.launch(server_name="0.0.0.0", server_port=7860)