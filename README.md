# ğŸº YaYan-AI (é›…è¨€)

![Python](https://img.shields.io/badge/Python-3.10-blue)
![GPU](https://img.shields.io/badge/GPU-RTX%203090-green)
![License](https://img.shields.io/badge/License-MIT-orange)

> **Local Dialect Conversion Engine | æœ¬åœ°åŒ–æ–¹è¨€è½‰æ­£é«”ä¸­æ–‡ç³»çµ±**

## ğŸ“– Introduction (å°ˆæ¡ˆç°¡ä»‹)

**[English]**
**YaYan-AI** is a local, offline AI system capable of converting various Chinese dialects (e.g., Taiwanese, Cantonese, Sichuanese) into standard Traditional Chinese text. It leverages **Whisper-Large-v3** for high-fidelity Automatic Speech Recognition (ASR) and **Qwen-2.5-7B-Instruct** for context-aware dialect correction and translation.
Designed to run efficiently on a single **NVIDIA RTX 3090 (24GB)** using 4-bit quantization.

**[ä¸­æ–‡]**
**é›…è¨€ (YaYan-AI)** æ˜¯ä¸€å€‹åŸºæ–¼ NVIDIA RTX 3090 çš„æœ¬åœ°åŒ– AI ç³»çµ±ï¼Œè‡´åŠ›æ–¼æ¶ˆé™¤æ–¹è¨€éš”é–¡ï¼Œå°‡å£èªï¼ˆå¦‚å°ç£åœ‹èªã€ç²µèªã€å››å·è©±ï¼‰è½‰åŒ–ç‚ºæ¨™æº–çš„ã€Œé›…è¨€ã€ï¼ˆæ­£é«”ä¸­æ–‡æ›¸é¢èªï¼‰ã€‚
æœ¬å°ˆæ¡ˆçµåˆäº† **OpenAI Whisper-Large-v3** çš„å¼·å¤§è½åŠ›èˆ‡ **Qwen-2.5-7B** çš„æ·±åº¦ç†è§£èƒ½åŠ›ï¼Œåœ¨æœ¬åœ°ç«¯å¯¦ç¾é«˜éš±ç§ã€é«˜ç²¾åº¦çš„èªéŸ³é‡å¡‘ã€‚

---

## ğŸš€ Features (ç‰¹è‰²åŠŸèƒ½)

* **ğŸ™ï¸ High-Accuracy ASR (é«˜ç²¾åº¦è½å¯«)**
    * Uses `whisper-large-v3` to transcribe speech with high fidelity.
    * æ¡ç”¨ OpenAI æœ€æ–°æ¨¡å‹ï¼Œç²¾æº–æ•æ‰æ–¹è¨€ç™¼éŸ³ã€‚

* **ğŸ§  Dialect Correction (æ–¹è¨€è½‰æ­£)**
    * Uses `Qwen-2.5-7B` (LLM) to fix ASR errors and convert colloquialisms to formal text.
    * ä¿®æ­£èªéŸ³è­˜åˆ¥éŒ¯èª¤ï¼ˆå¦‚åŒéŸ³ç•°å­—ï¼‰ï¼Œä¸¦å°‡å£èªèªæ³•è½‰ç‚ºè¦ç¯„æ›¸é¢èªã€‚

* **ğŸ”’ Local Privacy (æœ¬åœ°éš±ç§)**
    * Everything runs locally on your GPU. No data is sent to the cloud.
    * å…¨ç¨‹åœ¨æœ¬åœ° RTX 3090 é‹ç®—ï¼Œæ•¸æ“šä¸ä¸Šé›²ç«¯ï¼Œé©åˆæ©Ÿæ•è³‡æ–™ã€‚

* **âš¡ Optimized Performance (æ•ˆèƒ½å„ªåŒ–)**
    * Implements `bitsandbytes` 4-bit quantization.
    * å¯¦ä½œ 4-bit é‡åŒ–æŠ€è¡“ï¼Œå–®å¡ 24GB é¡¯å­˜å³å¯æµæš¢é‹è¡Œå…©å¤§æ¨¡å‹ã€‚

---

## ğŸ› ï¸ Requirements (ç’°å¢ƒéœ€æ±‚)

* **OS:** Windows 10/11 (via WSL2 Ubuntu) or Linux
* **GPU:** NVIDIA GPU with 24GB VRAM (Recommended: RTX 3090 / 4090)
* **Driver:** CUDA 12.1+
* **Python:** 3.10 (Conda environment recommended)

---

## ğŸ“¦ Installation (å®‰è£æ­¥é©Ÿ)

### 1. Clone Repository (ä¸‹è¼‰å°ˆæ¡ˆ)
    
    git clone [https://github.com/YourUsername/YaYan-AI.git](https://github.com/YourUsername/YaYan-AI.git)
    cd YaYan-AI
    mkdir -p models_cache input_audio output_text
    
### 2. Create Environment (å»ºç«‹ç’°å¢ƒ)
    
    conda create -n dialect_env python=3.10 -y
    conda activate dialect_env
    
### 3. Install PyTorch (å®‰è£ PyTorch)
    
    pip install torch torchvision torchaudio --index-url [https://download.pytorch.org/whl/cu121](https://download.pytorch.org/whl/cu121)
    
### 4. Install Dependencies (å®‰è£æ ¸å¿ƒå¥—ä»¶)
    
    pip install transformers accelerate bitsandbytes peft gradio librosa scipy soundfile protobuf sentencepiece
    
## â–¶ï¸ Usage (ä½¿ç”¨æ–¹æ³•)
### 1. Start the System (å•Ÿå‹•ç³»çµ±)
    
    conda activate dialect_env
    python app.py
    
Note: The first run will automatically download models (~15GB). Please wait. æ³¨æ„ï¼š é¦–æ¬¡åŸ·è¡Œå°‡è‡ªå‹•ä¸‹è¼‰æ¨¡å‹ï¼ˆç´„ 15GBï¼‰ï¼Œè«‹è€å¿ƒç­‰å¾…é€²åº¦æ¢è·‘å®Œã€‚
    
### 2. Open Web UI (é–‹å•Ÿä»‹é¢)
Once the terminal shows the URL, open your browser and visit: ç•¶çµ‚ç«¯æ©Ÿé¡¯ç¤ºç¶²å€å¾Œï¼Œè«‹æ‰“é–‹ç€è¦½å™¨è¼¸å…¥ï¼š

http://localhost:7860

### 3. Batch Processing (æ‰¹æ¬¡è™•ç†)
Automatically process all files in input_audio/. è‡ªå‹•è½‰æ› input_audio è³‡æ–™å¤¾å…§æ‰€æœ‰éŸ³æª”ã€‚
    
    python auto_batch.py
    
## ğŸ—ï¸ Technical Stack (æŠ€è¡“æ¶æ§‹)
    
    ASR Model: openai/whisper-large-v3

    LLM Model: Qwen/Qwen2.5-7B-Instruct (Quantized: NF4)

    Acceleration: bitsandbytes (4-bit quantization)

    Interface: Gradio

## ğŸ“ License
    This project is open-source and available under the MIT License. 